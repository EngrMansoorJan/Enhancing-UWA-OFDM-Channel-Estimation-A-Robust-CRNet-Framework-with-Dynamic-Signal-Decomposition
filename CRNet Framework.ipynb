{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550189a-ac41-474d-886b-72595e76a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv1D, LSTM, Dense, Dropout, \n",
    "                                     Reshape, Concatenate, Layer)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 1: Complex Channel Output Layer \n",
    "# Paper Eq. 16: \\(\\hat{h}_i = \\sum_{d=1}^D (W_{i,d}^{(r)} + jW_{i,d}^{(i)})h_d^{final} + b_i^{(r)} + jb_i^{(i)}\\)\n",
    "# -----------------------------------------------------------------------------\n",
    "class ComplexChannelOutputLayer(Layer):\n",
    "    def __init__(self, num_subcarriers, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_subcarriers = num_subcarriers  # N = 1024 (Table 4: Number of Subcarriers)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Input shape: (batch_size, D) where D = 64 (2nd LSTM's hidden units)\n",
    "        D = input_shape[-1]\n",
    "        # Real part weights/biases: W^{(r)}, b^{(r)}\n",
    "        self.W_real = self.add_weight(\n",
    "            shape=(D, self.num_subcarriers),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            name=\"W_real\"\n",
    "        )\n",
    "        self.b_real = self.add_weight(\n",
    "            shape=(self.num_subcarriers,),\n",
    "            initializer=\"zeros\",\n",
    "            name=\"b_real\"\n",
    "        )\n",
    "        # Imaginary part weights/biases: W^{(i)}, b^{(i)}\n",
    "        self.W_imag = self.add_weight(\n",
    "            shape=(D, self.num_subcarriers),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            name=\"W_imag\"\n",
    "        )\n",
    "        self.b_imag = self.add_weight(\n",
    "            shape=(self.num_subcarriers,),\n",
    "            initializer=\"zeros\",\n",
    "            name=\"b_imag\"\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # inputs: Final hidden state of 2nd LSTM (h_final: batch_size × D)\n",
    "        h_final = inputs\n",
    "        # Compute real and imaginary parts of \\(\\hat{h}_i\\)\n",
    "        h_real = tf.matmul(h_final, self.W_real) + self.b_real  # batch_size × N\n",
    "        h_imag = tf.matmul(h_final, self.W_imag) + self.b_imag  # batch_size × N\n",
    "        # Combine into complex channel coefficients (shape: batch_size × N × 2)\n",
    "        # Axis 2: [0] = real, [1] = imaginary (for consistency with data format)\n",
    "        return tf.stack([h_real, h_imag], axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_subcarriers\": self.num_subcarriers})\n",
    "        return config\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 2: Build CRNet Model \n",
    "# -----------------------------------------------------------------------------\n",
    "def build_crnet(num_subcarriers=1024,  # Table 4: Number of OFDM Subcarriers\n",
    "                pilot_dim=10,         # num = 10 (1-167: input shape (1152,1024,10))\n",
    "                conv_filters=64,       #  64 filters per Conv1D\n",
    "                conv_kernel=3,         #  kernel size 3\n",
    "                lstm_units=64,         #  64 units per LSTM\n",
    "                dense_units=128,       #  128 units in Dense layer\n",
    "                dropout_rate=0.2):     #  dropout = 0.2\n",
    "    \n",
    "    # ----------------------\n",
    "    # Input Layer \n",
    "    # Input 1: Received OFDM signal (shape: (batch_size, time_steps, num_subcarriers, pilot_dim))\n",
    "    # Paper input shape: (N_t=1152, N_fft=1024, num=10) → time_steps=1152, num_subcarriers=1024, pilot_dim=10\n",
    "    input_received = Input(\n",
    "        shape=(None, num_subcarriers, pilot_dim),  # None = variable time_steps (1152)\n",
    "        name=\"input_received_signal\"\n",
    "    )\n",
    "    \n",
    "    # Input 2: Transmitted pilot symbols (X_p(k); shape: (batch_size, time_steps, num_subcarriers))\n",
    "    input_pilots = Input(\n",
    "        shape=(None, num_subcarriers),\n",
    "        name=\"input_transmitted_pilots\"\n",
    "    )\n",
    "    \n",
    "    # ----------------------\n",
    "    # Reshape Inputs for Conv1D \n",
    "    # Combine \"num_subcarriers\" and \"pilot_dim\" into a single feature dimension for Conv1D\n",
    "    # New shape: (batch_size, time_steps, num_subcarriers × pilot_dim)\n",
    "    x = Reshape((-1, num_subcarriers * pilot_dim))(input_received)\n",
    "    # Concatenate received signal with pilot symbols (paper: 1-108: train with received + transmitted pilots)\n",
    "    x = Concatenate(axis=-1)([x, input_pilots])  # Shape: (batch_size, time_steps, (num_subcarriers×pilot_dim) + num_subcarriers)\n",
    "    \n",
    "    # ----------------------\n",
    "    # Conv1D Layers \n",
    "    # 1st Conv1D Layer: 64 filters, kernel=3, ReLU\n",
    "    x = Conv1D(\n",
    "        filters=conv_filters,\n",
    "        kernel_size=conv_kernel,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        name=\"conv1d_1\"\n",
    "    )(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # 2nd Conv1D Layer: 64 filters, kernel=3, ReLU\n",
    "    x = Conv1D(\n",
    "        filters=conv_filters,\n",
    "        kernel_size=conv_kernel,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        name=\"conv1d_2\"\n",
    "    )(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # ----------------------\n",
    "    # LSTM Layers \n",
    "    # 1st LSTM: Returns full sequence (shape: (batch_size, time_steps, lstm_units))\n",
    "    x = LSTM(\n",
    "        units=lstm_units,\n",
    "        return_sequences=True,\n",
    "        name=\"lstm_1\"\n",
    "    )(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # 2nd LSTM: Returns final hidden state (shape: (batch_size, lstm_units))\n",
    "    x = LSTM(\n",
    "        units=lstm_units,\n",
    "        return_sequences=False,\n",
    "        name=\"lstm_2\"\n",
    "    )(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # ----------------------\n",
    "    # Dense Layer \n",
    "    x = Dense(\n",
    "        units=dense_units,\n",
    "        activation=\"relu\",\n",
    "        name=\"dense_1\"\n",
    "    )(x)\n",
    "    \n",
    "    # ----------------------\n",
    "    # Output Layer: Complex Channel Estimation\n",
    "    # Output shape: (batch_size, num_subcarriers, 2) → [real, imaginary] parts of \\(\\hat{h}_i\\)\n",
    "    output_channel = ComplexChannelOutputLayer(\n",
    "        num_subcarriers=num_subcarriers,\n",
    "        name=\"output_complex_channel\"\n",
    "    )(x)\n",
    "    \n",
    "    # ----------------------\n",
    "    # Define Model\n",
    "    crnet = Model(\n",
    "        inputs=[input_received, input_pilots],\n",
    "        outputs=output_channel,\n",
    "        name=\"CRNet\"\n",
    "    )\n",
    "    \n",
    "    # ----------------------\n",
    "    # Compile Model \n",
    "    optimizer = Adam(learning_rate=1e-3)  # Adam, lr=0.001\n",
    "    loss = MeanSquaredError(name=\"mse_loss\")  # MSE loss \n",
    "    crnet.compile(optimizer=optimizer, loss=loss, metrics=[\"mse\"])\n",
    "    \n",
    "    return crnet\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 3: Generate Synthetic Training Data (Matches Paper's Bellhop Dataset)\n",
    "# Dataset generated via Bellhop ray-tracing (6000 samples, 80%/20% split)\n",
    "# -----------------------------------------------------------------------------\n",
    "def generate_bellhop_like_data(num_samples=6000,    # 6000 samples per channel\n",
    "                               time_steps=1152,     #  N_t=1152\n",
    "                               num_subcarriers=1024,# Table 4: 1024 subcarriers\n",
    "                               pilot_dim=10):       #  num=10\n",
    "    \n",
    "    # Input 1: Received OFDM signal (shape: (num_samples, time_steps, num_subcarriers, pilot_dim))\n",
    "    # Simulate Bellhop-like multipath + noise \n",
    "    received_signal = np.random.normal(\n",
    "        loc=0, scale=0.5,\n",
    "        size=(num_samples, time_steps, num_subcarriers, pilot_dim)\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    # Input 2: Transmitted pilot symbols (shape: (num_samples, time_steps, num_subcarriers))\n",
    "    # Paper: 1-108: pilot symbols are known (QPSK: 1+1j, -1+1j, etc. → real part used here)\n",
    "    pilots = np.random.choice([-1.0, 1.0], size=(num_samples, time_steps, num_subcarriers)).astype(np.float32)\n",
    "    \n",
    "    # Ground Truth: True Channel Impulse Response (CIR) → complex coefficients (real + imaginary)\n",
    "    # Shape: (num_samples, num_subcarriers, 2) → [real, imaginary]\n",
    "    true_channel = np.random.normal(\n",
    "        loc=0, scale=0.1,\n",
    "        size=(num_samples, num_subcarriers, 2)\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    # Split into train (80%) and validation (20%) (1-170)\n",
    "    split_idx = int(num_samples * 0.8)\n",
    "    train_data = (\n",
    "        [received_signal[:split_idx], pilots[:split_idx]],  # train inputs\n",
    "        true_channel[:split_idx]                            # train labels\n",
    "    )\n",
    "    val_data = (\n",
    "        [received_signal[split_idx:], pilots[split_idx:]],  # val inputs\n",
    "        true_channel[split_idx:]                            # val labels\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 4: Train CRNet (Matches Paper's Training Parameters)\n",
    "#  100 epochs, batch size=64, early stopping (patience=5)\n",
    "# -----------------------------------------------------------------------------\n",
    "def train_crnet(crnet_model, train_data, val_data, batch_size=64, epochs=100):\n",
    "    # Callbacks ( early stopping with patience=5)\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            #filepath=\"crnet_best_model.h5\",\n",
    "            #monitor=\"val_loss\",\n",
    "            #save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = crnet_model.fit(\n",
    "        x=train_data[0],\n",
    "        y=train_data[1],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 5: (Initialize, Generate Data, Train)\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Initialize CRNet (all params from paper)\n",
    "    crnet = build_crnet(\n",
    "        num_subcarriers=1024,  # Table 4\n",
    "        pilot_dim=10,          \n",
    "        conv_filters=64,       \n",
    "        conv_kernel=3,         \n",
    "        lstm_units=64,         \n",
    "        dense_units=128,       \n",
    "        dropout_rate=0.2       \n",
    "    )\n",
    "    crnet.summary()  # Print model architecture (verify layers/params)\n",
    "    \n",
    "    # 2. Generate Bellhop-like training/validation data (paper: 1-162-169)\n",
    "    train_data, val_data = generate_bellhop_like_data(\n",
    "        num_samples=6000,    #  6000 samples\n",
    "        time_steps=1152,     #  N_t=1152\n",
    "        num_subcarriers=1024,\n",
    "        pilot_dim=10\n",
    "    )\n",
    "    \n",
    "    # 3. Train CRNet \n",
    "    history = train_crnet(\n",
    "        crnet_model=crnet,\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        batch_size=64,  \n",
    "        epochs=100      \n",
    "    )\n",
    "    \n",
    "    # 4. Example Inference (Estimate Channel from New Data)\n",
    "    # Generate a single test sample (shape: (1, time_steps, num_subcarriers, pilot_dim))\n",
    "    test_received = np.random.normal(0, 0.5, (1, 1152, 1024, 10)).astype(np.float32)\n",
    "    test_pilots = np.random.choice([-1.0, 1.0], (1, 1152, 1024)).astype(np.float32)\n",
    "    # Predict complex channel coefficients\n",
    "    estimated_channel = crnet.predict([test_received, test_pilots], verbose=1)\n",
    "    print(f\"\\nEstimated Channel Shape: {estimated_channel.shape} → (batch_size, num_subcarriers, [real, imaginary])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8174e-195e-4f66-b7d4-a261a0138610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
